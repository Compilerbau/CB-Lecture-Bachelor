<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Parser on </title>
    <link>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1165993/parsing/</link>
    <description>Recent content in Parser on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>de-DE</language><atom:link href="https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1165993/parsing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CFG</title>
      <link>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1165993/parsing/cfg/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1165993/parsing/cfg/</guid>
      <description>Wiederholung Endliche Automaten. reguläre Ausdrücke, reguläre Grammatiken, reguläre Sprachen  Wie sind DFAs und NFAs definiert? Was sind reguläre Ausdrücke? Was sind formale und reguläre Grammatiken? In welchem Zusammenhang stehen all diese Begriffe? Wie werden DFAs und reguläre Ausdrücke im Compilerbau eingesetzt?  Motivation Wofür reichen reguläre Sprachen nicht? Für z. B. alle Sprachen, in deren Wörtern Zeichen über eine Konstante hinaus gezählt werden müssen. Diese Sprachen lassen sich oft mit Variablen im Exponenten beschreiben, die unendlich viele Werte annehmen können.</description>
    </item>
    <item>
      <title>LL-Parser</title>
      <link>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1165993/parsing/ll-parser-theory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1165993/parsing/ll-parser-theory/</guid>
      <description>Wiederholung Motivation Themen für heute  Der Einsatz kontextfreier Grammatik zur Syntaxanalyse mittels Top-Down-Techniken  Syntaxanalyse Syntax Wir verstehen unter Syntax eine Menge von Regeln, die die Struktur von Daten (z. B. Programmen) bestimmen.
Syntaxanalyse ist die Bestimmung, ob Eingabedaten einer vorgegebenen Syntax entsprechen.
Arten der Syntaxanalyse Die Syntax bezieht sich auf die Struktur der zu analysierenden Eingabe, z. B. einem Computerprogramm in einer Hochsprache. Diese Struktur wird mit formalen Grammatiken beschrieben.</description>
    </item>
    <item>
      <title>LL-Parser selbst implementiert</title>
      <link>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1165993/parsing/ll-parser-impl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1165993/parsing/ll-parser-impl/</guid>
      <description>Erinnerung Lexer: Zeichenstrom $\to$ Tokenstrom def nextToken(): while (peek != EOF): # globale Variable, über consume() switch (peek): case &amp;#39; &amp;#39;: case &amp;#39;\t&amp;#39;: case &amp;#39;\n&amp;#39;: WS(); continue case &amp;#39;[&amp;#39;: consume(); return Token(LBRACK, &amp;#39;[&amp;#39;) ... default: raise Error(&amp;#34;invalid character: &amp;#34;+peek) return Token(EOF_Type, &amp;#34;&amp;lt;EOF&amp;gt;&amp;#34;) def match(c): # Lookahead: Ein Zeichen consume() if (peek == c): return True else: rollBack(); return False def consume(): peek = buffer[start] start = (start+1) mod 2n if (start mod n == 0): fill(buffer[start:start+n-1]) end = (start+n) mod 2n Erinnerung: Der Lexer arbeitet direkt auf dem Zeichenstrom und versucht über längste Matches daraus einen Tokenstrom zu erzeugen.</description>
    </item>
    <item>
      <title>ANTLR (Parsergenerator)</title>
      <link>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1165993/parsing/antlr/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1165993/parsing/antlr/</guid>
      <description>ANTLR (Parsergenerator) Wrap-Up TODO</description>
    </item>
    <item>
      <title>Error-Recovery</title>
      <link>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1165993/parsing/recovery/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1165993/parsing/recovery/</guid>
      <description>Fehler beim Parsen  Quelle: BC George, Vorlesung &amp;quot;Einführung in die Programmierung mit Skriptsprachen&amp;quot;, CC BY-SA 4.0
 Compiler ist ein schnelles Mittel zum Finden von (syntaktischen) Fehlern Wichtige Eigenschaften:  Reproduzierbare Ergebnisse Aussagekräftige Fehlermeldungen Nach Erkennen eines Fehlers: (vorläufige) Korrektur und Parsen des restlichen Codes =&amp;gt; weitere Fehler anzeigen. Problem: Bis wohin &amp;quot;gobbeln&amp;quot;, d.h. was als Synchronisationspunkt nehmen? Semikolon? Syntaktisch fehlerhafte Programme dürfen nicht in die Zielsprache übersetzt werden!    Typische Fehler beim Parsing grammar VarDef; alt : stmt | stmt2 ; stmt : &amp;#39;int&amp;#39; ID &amp;#39;;&amp;#39; ; stmt2 : &amp;#39;int&amp;#39; ID &amp;#39;=&amp;#39; ID &amp;#39;;&amp;#39; ; ANTLR4: VarDef.</description>
    </item>
    <item>
      <title>Grenze Lexer und Parser</title>
      <link>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1165993/parsing/finalwords/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fh-bielefeld.de/elearning/data/FH-Bielefeld/lm_data/lm_1165993/parsing/finalwords/</guid>
      <description>Grenze Lexer und Parser (Faustregeln) Der Lexer verwendet einfache reguläre Ausdrücke, während der Parser mit Lookaheads unterschiedlicher Größe, Backtracking und umfangreicher Error-Recovery arbeitet. Entsprechend sollte man alle Arbeit, die man bereits im Lexer erledigen kann, auch dort erledigen. Oder andersherum: Man sollte dem Parser nicht unnötige Arbeit aufbürden.
=&amp;gt; Erreiche in jeder Verarbeitungsstufe die maximal mögliche Abstraktionsstufe!
  Matche und verwerfe im Lexer alles, was der Parser nicht braucht.</description>
    </item>
  </channel>
</rss>